NPLM은 벤지오 연구팀에서 제안한 기법

NLPM 이전의 언어 모델들은 대부분 통계기반의 순차적 언어모델.
(언어는 앞에서 뒤로 쓰느 Sequential 데이터이기 때문에 이런 통계기반의 연구가 많았던 것으로 생각됨)

이전 연구들의 단점
1. 정답데이터를 분석하여 확률기반으로 처리했기 때문에 unseen 데이터에 대해 처리가 어려웠었다.
2. 긴 문장에 대해 분석하기 어렵다. Context size를 5이상 조절하기 어려움.
3. 단어/문장간 유사도 계산이 어려움

NPLM의 아이디어
직전까지 나온 단어들로 현재 나올 단어를 유추하는 것.

##p(w_t|w_t-1,...,w_t-n+1) = \sum\limit_{i}\frac{exp(y_w_t)}{exp(y_i)}

이전의 각 츨현 단어의 순서는 적용하지 않았다. 대용량의 데이터가 있으면, 결국 대상데이터와 연관있는 데이터가 영향력이 쎌 것.

단어들의 벡터는 랜덤하게 제공하고 이전 단어들의 벡터들을 concatenate(붙임)해서 입력으로 사용.

과적합이고, 계산량이 많은 문제가 있지만, 통계기반의 연구에서 해내지 못한 unseen데이터의 확률 값 0을 비슷한 문맥으로 유추하여 0이 아니게 되고 계산이 가능해진다
